{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad27a295-2824-414e-9147-c21a36992d6a",
     "showTitle": false,
     "title": ""
    },
    "id": "_5pP76M0Ny-b"
   },
   "source": [
    "### Size-up experiment on Feb 2024 Yellow Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bcc3d63-7914-4146-919c-efc501af7985",
     "showTitle": false,
     "title": ""
    },
    "id": "IazjNdy-Ny-e"
   },
   "outputs": [],
   "source": [
    "global c\n",
    "c = 8 # for size-up, fix at 8 cores\n",
    "sizes = [10, 20, 40, 80, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2b6bf1d-592f-4b2a-9df9-91b6c68457c6",
     "showTitle": false,
     "title": ""
    },
    "id": "IzTOYIQaNy-d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql.types import DoubleType, DateType\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3872af02-6cc3-4229-ba56-e4f98b28b469",
     "showTitle": false,
     "title": ""
    },
    "id": "06dJr5tlShC0"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(f\"local[*]\") \\\n",
    "    .appName(\"Local LR with {c} partitions\") \\\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# swith the latest spark version to older one so that it tolerates some data format issues\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "\"\"\"\n",
    "in order to avoid \"Parquet column cannot be converted\" error, we need to disable vectorized reader when we have decimal values in our columns.\n",
    "refer to https://learn.microsoft.com/en-us/answers/questions/853861/parquet-column-cannot-be-converted for further info\n",
    "\"\"\"\n",
    "# spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c70dd1f9-6b70-4b6c-811a-876fb3ab2665",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "om8gFpg66ueO",
    "outputId": "b76c4289-20aa-4465-b476-450b4c577da0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = '/mnt/2024-team14/yellow_taxi'\n",
    "\n",
    "cols = [ # cols to rename and reformat\n",
    "    (\"tpep_pickup_datetime\", \"Date\", DateType()),\n",
    "    (\"trip_distance\", \"trip_miles\", DoubleType()),\n",
    "    (\"fare_amount\", \"base_passenger_fare\", DoubleType())\n",
    "]\n",
    "\n",
    "# Read the Parquet file with schema inference\n",
    "df = spark.read.parquet(directory) \\\n",
    ".select(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\", \"fare_amount\")\n",
    "\n",
    "df = df.withColumns({n: F.col(o).cast(t) for o, n, t in cols}) \\\n",
    ".withColumns({\n",
    "  \"trip_time\": F.unix_timestamp(F.col(\"tpep_dropoff_datetime\")) - F.unix_timestamp(F.col(\"tpep_pickup_datetime\")),\n",
    "  \"trip_km\": F.col(\"trip_miles\") * 0.621371\n",
    "  }) \\\n",
    "  .drop(*[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\", \"trip_miles\", \"Date\", \"fare_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48514d30-e6ca-4380-ab80-bd5b73fc510c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df4de1bd-6338-487e-a326-7796eacd18e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b5469c-0dca-44c9-8acc-d68dda6b87e8",
     "showTitle": false,
     "title": ""
    },
    "id": "Ph2GWfU_QnPy"
   },
   "outputs": [],
   "source": [
    "column_names = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85bd7350-cdf5-4883-9341-bc813194858b",
     "showTitle": false,
     "title": ""
    },
    "id": "xcCfJRO3Ny-e"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time\n",
    "\n",
    "def build_model(partition_data_iter):\n",
    "  start = time.time()\n",
    "\n",
    "  partition_data_df = pd.DataFrame(partition_data_iter, columns=column_names)\n",
    "  reg = DecisionTreeRegressor(max_depth=5)\n",
    "  X_train = partition_data_df[['trip_km', 'trip_time']]\n",
    "  y_train = partition_data_df[\"base_passenger_fare\"]\n",
    "  model = reg.fit(X_train.values,y_train.values)\n",
    "\n",
    "  end = time.time()\n",
    "  return [(model, end - start)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4af990-c8c2-4ccf-97fb-2049dc8807c4",
     "showTitle": false,
     "title": ""
    },
    "id": "1AkwOmhxNy-e"
   },
   "outputs": [],
   "source": [
    "for i in range(10): # experiment 10 times\n",
    "  for fraction in sizes:\n",
    "    sample_df = df.sample(fraction/100)\n",
    "    # split data into train and test\n",
    "    train, test = sample_df.randomSplit([0.7, 0.3], seed=555)\n",
    "\n",
    "    train_rdd = train.rdd.repartition(c).cache()\n",
    "    test_rdd = test.rdd.repartition(c)\n",
    "\n",
    "    train_rdd.count()\n",
    "\n",
    "    start = time.time()\n",
    "    models_runtimes = train_rdd.mapPartitions(build_model).collect()\n",
    "\n",
    "    _, runtimes = zip(*models_runtimes)\n",
    "    end = time.time()\n",
    "\n",
    "    # Printing at the end of the file a log with the number of cores, percentage,\n",
    "    # building time and average runtime of mapPartitions:\n",
    "    percentage = fraction\n",
    "    with open(\"sizeup_dt.csv\", \"a\") as f:\n",
    "        print(\n",
    "            f\"{c},{percentage},{end - start},{sum(runtimes)/len(runtimes)}\",\n",
    "            file=f,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "local_dt_size_up",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
